Client Machine - 
    POST Request to HeadNode : model name & image files

HeadNode / NGINX - loadbalancer
    
GPU Nodes - execute inference task with image files
    Steps
    Run docker image